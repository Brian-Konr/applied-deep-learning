{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADL HW1 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12922050/miniconda3/envs/adl_hw1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset swag (/home/guest/r12922050/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "100%|██████████| 3/3 [00:00<00:00, 480.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 73546\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 20006\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 20005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "swag = load_dataset('swag', 'regular')\n",
    "\n",
    "# take a look at swag dataset to see what it looks like\n",
    "swag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593f14f960d971e294af884f0194b3a7</td>\n",
       "      <td>舍本和誰的數據能推算出連星的恆星的質量？</td>\n",
       "      <td>[2018, 6952, 8264, 836]</td>\n",
       "      <td>836</td>\n",
       "      <td>{'text': '斯特魯維', 'start': 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acd5d763ec4c250f9a11eac1412d6814</td>\n",
       "      <td>在關西鎮以什麼方言為主？</td>\n",
       "      <td>[1716, 8318, 4070, 7571]</td>\n",
       "      <td>8318</td>\n",
       "      <td>{'text': '四縣腔客家話', 'start': 306}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5670000714a658c5e52658e22e6985f7</td>\n",
       "      <td>「有錫兵，天下爭。無錫寧，天下清。」指的是何人攻破蘭陵後，率軍駐無錫錫山時的上書?</td>\n",
       "      <td>[6043, 5950, 2548, 5806]</td>\n",
       "      <td>5806</td>\n",
       "      <td>{'text': '王翦', 'start': 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f71493751ccfce42aae7a99ed3f20dbb</td>\n",
       "      <td>《方法論》的作者是誰?</td>\n",
       "      <td>[5443, 6843, 8584, 4350]</td>\n",
       "      <td>6843</td>\n",
       "      <td>{'text': '阿基米德', 'start': 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56d547357d11a8938197072d82aa126c</td>\n",
       "      <td>環繞速度又為哪種速度的別稱?</td>\n",
       "      <td>[1859, 7590, 3116, 8989]</td>\n",
       "      <td>7590</td>\n",
       "      <td>{'text': '第一宇宙速度', 'start': 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21709</th>\n",
       "      <td>0ba8689b6665bb8d700807e586244018</td>\n",
       "      <td>又稱爲虎斑的為什麼?</td>\n",
       "      <td>[5662, 68, 7394, 92]</td>\n",
       "      <td>7394</td>\n",
       "      <td>{'text': '土衛二', 'start': 213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21710</th>\n",
       "      <td>9405202eb2a8391136a5905987ebab26</td>\n",
       "      <td>愛爾蘭王國的王位在哪一年正式獲得神權認可?</td>\n",
       "      <td>[641, 6490, 3870, 2146]</td>\n",
       "      <td>3870</td>\n",
       "      <td>{'text': '1555年', 'start': 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21711</th>\n",
       "      <td>8dda88faa2c6b074a48b66cb74662727</td>\n",
       "      <td>《自題小像》是誰的作品?</td>\n",
       "      <td>[1991, 3309, 4956, 6311]</td>\n",
       "      <td>1991</td>\n",
       "      <td>{'text': '魯迅', 'start': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>92484786f021da4ed4dcf952401a7402</td>\n",
       "      <td>日蝕和月蝕在何時代就可以被算出來了？</td>\n",
       "      <td>[2745, 5391, 928, 4386]</td>\n",
       "      <td>928</td>\n",
       "      <td>{'text': '古希臘', 'start': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21713</th>\n",
       "      <td>7faf3194e307cde1832a21c2d999fa17</td>\n",
       "      <td>牛津大學在2004年與哪家公司合作進行大規模的數位化系統更新項目？</td>\n",
       "      <td>[1502, 8215, 1156, 8824]</td>\n",
       "      <td>1156</td>\n",
       "      <td>{'text': '谷歌', 'start': 235}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21714 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0      593f14f960d971e294af884f0194b3a7   \n",
       "1      acd5d763ec4c250f9a11eac1412d6814   \n",
       "2      5670000714a658c5e52658e22e6985f7   \n",
       "3      f71493751ccfce42aae7a99ed3f20dbb   \n",
       "4      56d547357d11a8938197072d82aa126c   \n",
       "...                                 ...   \n",
       "21709  0ba8689b6665bb8d700807e586244018   \n",
       "21710  9405202eb2a8391136a5905987ebab26   \n",
       "21711  8dda88faa2c6b074a48b66cb74662727   \n",
       "21712  92484786f021da4ed4dcf952401a7402   \n",
       "21713  7faf3194e307cde1832a21c2d999fa17   \n",
       "\n",
       "                                        question                paragraphs  \\\n",
       "0                           舍本和誰的數據能推算出連星的恆星的質量？   [2018, 6952, 8264, 836]   \n",
       "1                                   在關西鎮以什麼方言為主？  [1716, 8318, 4070, 7571]   \n",
       "2      「有錫兵，天下爭。無錫寧，天下清。」指的是何人攻破蘭陵後，率軍駐無錫錫山時的上書?  [6043, 5950, 2548, 5806]   \n",
       "3                                    《方法論》的作者是誰?  [5443, 6843, 8584, 4350]   \n",
       "4                                 環繞速度又為哪種速度的別稱?  [1859, 7590, 3116, 8989]   \n",
       "...                                          ...                       ...   \n",
       "21709                                 又稱爲虎斑的為什麼?      [5662, 68, 7394, 92]   \n",
       "21710                      愛爾蘭王國的王位在哪一年正式獲得神權認可?   [641, 6490, 3870, 2146]   \n",
       "21711                               《自題小像》是誰的作品?  [1991, 3309, 4956, 6311]   \n",
       "21712                         日蝕和月蝕在何時代就可以被算出來了？   [2745, 5391, 928, 4386]   \n",
       "21713          牛津大學在2004年與哪家公司合作進行大規模的數位化系統更新項目？  [1502, 8215, 1156, 8824]   \n",
       "\n",
       "       relevant                            answer  \n",
       "0           836    {'text': '斯特魯維', 'start': 108}  \n",
       "1          8318  {'text': '四縣腔客家話', 'start': 306}  \n",
       "2          5806       {'text': '王翦', 'start': 46}  \n",
       "3          6843     {'text': '阿基米德', 'start': 63}  \n",
       "4          7590   {'text': '第一宇宙速度', 'start': 69}  \n",
       "...         ...                               ...  \n",
       "21709      7394     {'text': '土衛二', 'start': 213}  \n",
       "21710      3870    {'text': '1555年', 'start': 47}  \n",
       "21711      1991        {'text': '魯迅', 'start': 0}  \n",
       "21712       928       {'text': '古希臘', 'start': 0}  \n",
       "21713      1156      {'text': '谷歌', 'start': 235}  \n",
       "\n",
       "[21714 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer my dataset to data format like swag\n",
    "\n",
    "import pandas as pd\n",
    "train_data = pd.read_json('./data/train.json')\n",
    "\n",
    "# take a look at train_data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鼓是一種打擊樂器，也是一種通訊工具，非洲某些部落用以傳達信息，中國古代軍隊用以發號施令。堅固...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>這次出售的贖罪券很特別，是全大赦贖罪券，可以贖買過去所犯的罪攢下來的所有刑罰，將購買者重新恢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>處在千年古都的西安交大校園少不了和歷史千絲萬縷的聯繫。興慶校區所處位置為唐長安城內的道政、常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>福臨於1651年親政後，他的母親昭聖慈壽皇太后安排兒子娶她的侄女額爾德尼奔巴，但福臨於165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>盧克萊修生於共和國末期，唯一的傳世之作《物性論》共六卷，每卷千餘行，是一部哲理詩。全詩著重闡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9008</th>\n",
       "      <td>在握網球拍的方式中，東方式正手握拍法如同我們與對方握手的姿勢一樣，先把手平貼在拍面上，保持手...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>雖然認識到了狹義相對論需要推廣為廣義相對論，並確立了兩條基本原理，愛因斯坦仍然為探索這一新理...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>因岳陽地處長江要道，自古被貶的遷客騷人多匯聚與此然後轉道，溯長江而上可至巴、蜀一帶，由湘江而...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>因為生物族群呈指數成長，但資源有限，因此不是每個個體都能存活。影響存活率的因素包括無機環境，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>針對天體攝影的天體攝影術誕生於1840年，當時約翰·威廉·德雷伯使用銀版照相法對月球進行攝影...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9013 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     鼓是一種打擊樂器，也是一種通訊工具，非洲某些部落用以傳達信息，中國古代軍隊用以發號施令。堅固...\n",
       "1     這次出售的贖罪券很特別，是全大赦贖罪券，可以贖買過去所犯的罪攢下來的所有刑罰，將購買者重新恢...\n",
       "2     處在千年古都的西安交大校園少不了和歷史千絲萬縷的聯繫。興慶校區所處位置為唐長安城內的道政、常...\n",
       "3     福臨於1651年親政後，他的母親昭聖慈壽皇太后安排兒子娶她的侄女額爾德尼奔巴，但福臨於165...\n",
       "4     盧克萊修生於共和國末期，唯一的傳世之作《物性論》共六卷，每卷千餘行，是一部哲理詩。全詩著重闡...\n",
       "...                                                 ...\n",
       "9008  在握網球拍的方式中，東方式正手握拍法如同我們與對方握手的姿勢一樣，先把手平貼在拍面上，保持手...\n",
       "9009  雖然認識到了狹義相對論需要推廣為廣義相對論，並確立了兩條基本原理，愛因斯坦仍然為探索這一新理...\n",
       "9010  因岳陽地處長江要道，自古被貶的遷客騷人多匯聚與此然後轉道，溯長江而上可至巴、蜀一帶，由湘江而...\n",
       "9011  因為生物族群呈指數成長，但資源有限，因此不是每個個體都能存活。影響存活率的因素包括無機環境，...\n",
       "9012  針對天體攝影的天體攝影術誕生於1840年，當時約翰·威廉·德雷伯使用銀版照相法對月球進行攝影...\n",
       "\n",
       "[9013 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loda context.json\n",
    "context_data = pd.read_json('./data/context.json')\n",
    "\n",
    "# take a look at context_data\n",
    "context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            593f14f960d971e294af884f0194b3a7\n",
       "question                  舍本和誰的數據能推算出連星的恆星的質量？\n",
       "paragraphs             [2018, 6952, 8264, 836]\n",
       "relevant                                   836\n",
       "answer          {'text': '斯特魯維', 'start': 108}\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first row of train_data\n",
    "train_data.iloc[0]\n",
    "# paragraphs are 4 context ids that represent 4 possible choices, and the id can refer to context.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first row of swag\n",
    "swag['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593f14f960d971e294af884f0194b3a7</td>\n",
       "      <td>舍本和誰的數據能推算出連星的恆星的質量？</td>\n",
       "      <td>[2018, 6952, 8264, 836]</td>\n",
       "      <td>836</td>\n",
       "      <td>{'text': '斯特魯維', 'start': 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acd5d763ec4c250f9a11eac1412d6814</td>\n",
       "      <td>在關西鎮以什麼方言為主？</td>\n",
       "      <td>[1716, 8318, 4070, 7571]</td>\n",
       "      <td>8318</td>\n",
       "      <td>{'text': '四縣腔客家話', 'start': 306}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5670000714a658c5e52658e22e6985f7</td>\n",
       "      <td>「有錫兵，天下爭。無錫寧，天下清。」指的是何人攻破蘭陵後，率軍駐無錫錫山時的上書?</td>\n",
       "      <td>[6043, 5950, 2548, 5806]</td>\n",
       "      <td>5806</td>\n",
       "      <td>{'text': '王翦', 'start': 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f71493751ccfce42aae7a99ed3f20dbb</td>\n",
       "      <td>《方法論》的作者是誰?</td>\n",
       "      <td>[5443, 6843, 8584, 4350]</td>\n",
       "      <td>6843</td>\n",
       "      <td>{'text': '阿基米德', 'start': 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56d547357d11a8938197072d82aa126c</td>\n",
       "      <td>環繞速度又為哪種速度的別稱?</td>\n",
       "      <td>[1859, 7590, 3116, 8989]</td>\n",
       "      <td>7590</td>\n",
       "      <td>{'text': '第一宇宙速度', 'start': 69}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  593f14f960d971e294af884f0194b3a7   \n",
       "1  acd5d763ec4c250f9a11eac1412d6814   \n",
       "2  5670000714a658c5e52658e22e6985f7   \n",
       "3  f71493751ccfce42aae7a99ed3f20dbb   \n",
       "4  56d547357d11a8938197072d82aa126c   \n",
       "\n",
       "                                    question                paragraphs  \\\n",
       "0                       舍本和誰的數據能推算出連星的恆星的質量？   [2018, 6952, 8264, 836]   \n",
       "1                               在關西鎮以什麼方言為主？  [1716, 8318, 4070, 7571]   \n",
       "2  「有錫兵，天下爭。無錫寧，天下清。」指的是何人攻破蘭陵後，率軍駐無錫錫山時的上書?  [6043, 5950, 2548, 5806]   \n",
       "3                                《方法論》的作者是誰?  [5443, 6843, 8584, 4350]   \n",
       "4                             環繞速度又為哪種速度的別稱?  [1859, 7590, 3116, 8989]   \n",
       "\n",
       "   relevant                            answer  \n",
       "0       836    {'text': '斯特魯維', 'start': 108}  \n",
       "1      8318  {'text': '四縣腔客家話', 'start': 306}  \n",
       "2      5806       {'text': '王翦', 'start': 46}  \n",
       "3      6843     {'text': '阿基米德', 'start': 63}  \n",
       "4      7590   {'text': '第一宇宙速度', 'start': 69}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 rows of train_data\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "- for train and valid, use `load_dataset`\n",
    "- for context, it's a normal json file, use `pd.read_json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ed466149ca31f82a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/guest/r12922050/.cache/huggingface/datasets/json/default-ed466149ca31f82a/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 3276.80it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 253.96it/s]\n",
      "                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/guest/r12922050/.cache/huggingface/datasets/json/default-ed466149ca31f82a/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 716.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'paragraphs', 'relevant', 'answer'],\n",
       "        num_rows: 21714\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'paragraphs', 'relevant', 'answer'],\n",
       "        num_rows: 3009\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    'train': './data/train.json',\n",
    "    'validation': './data/valid.json',\n",
    "}\n",
    "\n",
    "my_datasets = load_dataset('json', data_files=data_files)\n",
    "my_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context.json\n",
    "- after reading it, rename it to paragraph_ref_map for index reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鼓是一種打擊樂器，也是一種通訊工具，非洲某些部落用以傳達信息，中國古代軍隊用以發號施令。堅固...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>這次出售的贖罪券很特別，是全大赦贖罪券，可以贖買過去所犯的罪攢下來的所有刑罰，將購買者重新恢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>處在千年古都的西安交大校園少不了和歷史千絲萬縷的聯繫。興慶校區所處位置為唐長安城內的道政、常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>福臨於1651年親政後，他的母親昭聖慈壽皇太后安排兒子娶她的侄女額爾德尼奔巴，但福臨於165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>盧克萊修生於共和國末期，唯一的傳世之作《物性論》共六卷，每卷千餘行，是一部哲理詩。全詩著重闡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9008</th>\n",
       "      <td>在握網球拍的方式中，東方式正手握拍法如同我們與對方握手的姿勢一樣，先把手平貼在拍面上，保持手...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>雖然認識到了狹義相對論需要推廣為廣義相對論，並確立了兩條基本原理，愛因斯坦仍然為探索這一新理...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>因岳陽地處長江要道，自古被貶的遷客騷人多匯聚與此然後轉道，溯長江而上可至巴、蜀一帶，由湘江而...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>因為生物族群呈指數成長，但資源有限，因此不是每個個體都能存活。影響存活率的因素包括無機環境，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>針對天體攝影的天體攝影術誕生於1840年，當時約翰·威廉·德雷伯使用銀版照相法對月球進行攝影...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9013 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     鼓是一種打擊樂器，也是一種通訊工具，非洲某些部落用以傳達信息，中國古代軍隊用以發號施令。堅固...\n",
       "1     這次出售的贖罪券很特別，是全大赦贖罪券，可以贖買過去所犯的罪攢下來的所有刑罰，將購買者重新恢...\n",
       "2     處在千年古都的西安交大校園少不了和歷史千絲萬縷的聯繫。興慶校區所處位置為唐長安城內的道政、常...\n",
       "3     福臨於1651年親政後，他的母親昭聖慈壽皇太后安排兒子娶她的侄女額爾德尼奔巴，但福臨於165...\n",
       "4     盧克萊修生於共和國末期，唯一的傳世之作《物性論》共六卷，每卷千餘行，是一部哲理詩。全詩著重闡...\n",
       "...                                                 ...\n",
       "9008  在握網球拍的方式中，東方式正手握拍法如同我們與對方握手的姿勢一樣，先把手平貼在拍面上，保持手...\n",
       "9009  雖然認識到了狹義相對論需要推廣為廣義相對論，並確立了兩條基本原理，愛因斯坦仍然為探索這一新理...\n",
       "9010  因岳陽地處長江要道，自古被貶的遷客騷人多匯聚與此然後轉道，溯長江而上可至巴、蜀一帶，由湘江而...\n",
       "9011  因為生物族群呈指數成長，但資源有限，因此不是每個個體都能存活。影響存活率的因素包括無機環境，...\n",
       "9012  針對天體攝影的天體攝影術誕生於1840年，當時約翰·威廉·德雷伯使用銀版照相法對月球進行攝影...\n",
       "\n",
       "[9013 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read context.json\n",
    "context_df = pd.read_json('./data/context.json')\n",
    "context_df\n",
    "\n",
    "paragraph_ref_map = {}\n",
    "# enumerate context_df\n",
    "for i, row in context_df.iterrows():\n",
    "    # add context_df to context\n",
    "    paragraph_ref_map[i] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_ref_map = {}\n",
    "# enumerate context_df\n",
    "for i, row in context_df.iterrows():\n",
    "    # add context_df to context\n",
    "    paragraph_ref_map[i] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鼓是一種打擊樂器，也是一種通訊工具，非洲某些部落用以傳達信息，中國古代軍隊用以發號施令。堅固的女的一面或雙面蒙上拉緊的膜。鼓可以用手或鼓杵敲擊出聲。鼓在非洲的傳統音樂以及在現代音樂中是一種比較重要的樂器，有的樂隊完全由以鼓為主的打擊樂器組成。鼓除了作為樂器外，在古代許多文明中還用鼓來傳播信息。不同類型的鼓，如定音鼓等，均被調校至特定的音調中。更常見的是將不同類型的鼓或打擊樂器互相組合，以構成常於流行音樂出現的爵士鼓。鼓的演奏一般是用手敲擊鼓面，或是用一二隻鼓棒或鼓錘敲擊。由於鼓的觸覺特性及其易於使用，在音樂治療中常用到鼓，特別是手鼓。在許多傳統文化中，鼓有其象徵的意義，也常用在宗教儀式中。像在蒲隆地的卡央達鼓是王權的象徵，卡央達鼓也出現在1962至1966年間的蒲隆地國旗中。在流行音樂或爵士樂中，鼓常常是指由一組鼓及銅鈸組成的爵士鼓，演奏者稱為鼓手。鼓幾乎都有一個圓形的開口，鼓面拉緊後可以固定在上面。但鼓身的形狀就有很多的變化，西洋樂器的鼓，鼓身多半都是圓柱體，但定音鼓的鼓身則是碗形，有些鼓的鼓身則是截角圓錐或是二個接合的截角圓錐。中國、日本、韓國的鼓常常是中間略寬、上下略窄的圓柱體。最早的鼓是出現於西元前六千年的兩河文明。\n",
      "盧克萊修生於共和國末期，唯一的傳世之作《物性論》共六卷，每卷千餘行，是一部哲理詩。全詩著重闡述伊壁鳩魯的哲學思想和德謨克利特的原子論，表示物質不滅、凡人不必懼怕死亡的生活觀。盧克萊修是古羅馬文學史上著名的智者，維吉爾曾稱羨慕他知曉事物的起因，是個幸福的人。卡圖魯斯生於義大利北部維羅那一個富有的家庭，經常出入羅馬上流社會，是黃金時代成就最高的抒情詩人。他是堅定不移的共和派，曾公然反對過愷撒，曾創作過許多辛辣的諷刺短詩。卡圖魯斯的詩作現存116首，他善用警句式的語言表達濃鬱熱烈、複雜微妙的感情。他的抒情詩對後世歐洲許多偉大詩人都產生過影響。賀拉斯出生於拍賣商家庭，是和卡圖魯斯齊名的抒情詩人。他幼年受過良好的教育，通曉拉丁語和希臘語，能誦荷馬史詩原文，併到雅典學過哲學。他的代表作品包括《長短句集》17首和《閒談集》18首。前者表明作者反對內戰，幻想黃金時代到來的思想；後者則諷刺羅馬社會的惡習。但賀拉斯最著名的作品是後期的《歌集》和《詩藝》。賀拉斯的抒情詩改造了希臘抒情詩的格律，構思巧妙，語言優美，優雅莊重，以有意、愛情、詩藝為題，融哲理和感情於一路，不少人競相模仿。《詩藝》則是古羅馬時期文藝理論上的最高成就，被古典主義文學視為經典。\n",
      "雖然認識到了狹義相對論需要推廣為廣義相對論，並確立了兩條基本原理，愛因斯坦仍然為探索這一新理論研究了八年之久。這期間他面臨的一個主要問題是缺乏有效的數學工具，直到1913年他在德國數學家馬塞爾·格羅斯曼的幫助下發表了一篇突破性的論文：《廣義相對論和重力理論綱要》，題目標註了物理部分作者為愛因斯坦，數學部分作者為格羅斯曼。這篇論文中原來單一的牛頓純量重力場被一個具有十個分量的四階對稱黎曼張量重力場替代，從此物理學中的時空不再是平直的，而成為了在全局上具有曲率但在局部平直的黎曼流形。1914年，愛因斯坦發表了《廣義相對論正式基礎》，其中他得到了廣義相對論中描述粒子運動的方程式：測地線方程式，並籍此推導了重力場中的光線偏折和重力紅移的結果。1915年11月，愛因斯坦發表了他最終推導出重力場方程式的四篇論文，其中《用廣義相對論解釋水星近日點運動》證明了廣義相對論能夠解釋自1859年以來困擾天文學家的水星的反常進動現象，而《重力場方程式》則正式給出了描述重力場和物質交互作用的愛因斯坦重力場方程式。\n"
     ]
    }
   ],
   "source": [
    "# check some ids\n",
    "print(paragraph_ref_map[0])\n",
    "print(paragraph_ref_map[4])\n",
    "print(paragraph_ref_map[9009])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: swag/regular\n",
      "Found cached dataset swag (/home/guest/r12922050/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "100%|██████████| 3/3 [00:00<00:00, 583.03it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"swag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2118.34ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 1]\n",
      "first sentences: [['Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.'], ['A drum line passes by walking down the street playing their instruments.', 'A drum line passes by walking down the street playing their instruments.', 'A drum line passes by walking down the street playing their instruments.', 'A drum line passes by walking down the street playing their instruments.'], ['A group of members in green uniforms walks waving flags.', 'A group of members in green uniforms walks waving flags.', 'A group of members in green uniforms walks waving flags.', 'A group of members in green uniforms walks waving flags.']]\n",
      "second sentences: [['A drum line passes by walking down the street playing their instruments.', 'A drum line has heard approaching them.', \"A drum line arrives and they're outside dancing and asleep.\", 'A drum line turns the lead singer watches the performance.'], ['Members of the procession are playing ping pong and celebrating one left each in quick.', 'Members of the procession wait slowly towards the cadets.', 'Members of the procession continues to play as well along the crowd along with the band being interviewed.', 'Members of the procession continue to play marching, interspersed.'], ['Members of the procession pay the other coaches to cheer as people this chatter dips in lawn sheets.', 'Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession is seen in the background.', 'Members of the procession are talking a couple of people playing a game of tug of war.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1992.54ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2]\n",
      "first sentences: [['Students lower their eyes nervously.', 'Students lower their eyes nervously.', 'Students lower their eyes nervously.', 'Students lower their eyes nervously.'], ['He rides the motorcycle down the hall and into the elevator.', 'He rides the motorcycle down the hall and into the elevator.', 'He rides the motorcycle down the hall and into the elevator.', 'He rides the motorcycle down the hall and into the elevator.'], ['The motorcyclist gets out of bed and prepares to leave by bathing using the bathroom and reading the newspaper.', 'The motorcyclist gets out of bed and prepares to leave by bathing using the bathroom and reading the newspaper.', 'The motorcyclist gets out of bed and prepares to leave by bathing using the bathroom and reading the newspaper.', 'The motorcyclist gets out of bed and prepares to leave by bathing using the bathroom and reading the newspaper.']]\n",
      "second sentences: [['She pats her shoulder, then saunters toward someone.', 'She turns with two students.', 'She walks slowly towards someone.', 'She wheels around as her dog thunders out.'], ['He looks at a mirror in the mirror as he watches someone walk through a door.', \"He stops, listening to a cup of coffee with the seated woman, who's standing.\", 'He exits the building and rides the motorcycle into a casino where he performs several tricks as people watch.', \"He pulls the bag out of his pocket and hands it to someone's grandma.\"], ['He shoots a look at her.', 'He makes his way past it and peers out a window.', 'He rides the motorcycle down the hall and into the elevator.', 'He sits on the ground beside her pants, clinging by a flannel wool.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2114.06ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1]\n",
      "first sentences: [['A person shows the bottom of a large dust mop.', 'A person shows the bottom of a large dust mop.', 'A person shows the bottom of a large dust mop.', 'A person shows the bottom of a large dust mop.'], ['The camera move and we see a man next to the lady.', 'The camera move and we see a man next to the lady.', 'The camera move and we see a man next to the lady.', 'The camera move and we see a man next to the lady.'], ['The lady stops and adjusts the camera.', 'The lady stops and adjusts the camera.', 'The lady stops and adjusts the camera.', 'The lady stops and adjusts the camera.']]\n",
      "second sentences: [['Then, the person places the scrub on the floor then cleans the soap evenly.', 'Then, the person cleans a gym with the large dust mop.', 'Then, the person stops and spray a car with some spray paint.', 'Then, the person places the bucket and a bucket.'], ['the lady stands on a bench in the bar.', 'the lady put a piece down on the table.', 'the lady fixes her hair in the camera.', 'the lady completes a picture and shows a standing room.'], ['the camera move and we see a man going down the street.', 'the camera move and we see a lady kick a scene.', 'the camera move and we see a man next to the lady.', 'the camera move and we see a closeup of her hair before sitting down again.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# trim samples\n",
    "for split in raw_datasets.keys():\n",
    "    raw_datasets[split] = raw_datasets[split].select(range(3))\n",
    "\n",
    "if raw_datasets[\"train\"] is not None:\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "else:\n",
    "    column_names = raw_datasets[\"validation\"].column_names\n",
    "\n",
    "ending_names = [f\"ending{i}\" for i in range(4)]\n",
    "context_name = \"sent1\"\n",
    "question_header_name = \"sent2\"\n",
    "label_column_name = \"label\" if \"label\" in column_names else \"labels\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 4 for context in examples[context_name]]\n",
    "    # size of first_sentences\n",
    "    question_headers = examples[question_header_name]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "    labels = examples[label_column_name]\n",
    "    print(labels)\n",
    "    print(f\"first sentences: {first_sentences}\")\n",
    "    print(f\"second sentences: {second_sentences}\")\n",
    "    # Flatten out\n",
    "    first_sentences = list(chain(*first_sentences))\n",
    "    second_sentences = list(chain(*second_sentences))\n",
    "\n",
    "processed_datasets = raw_datasets.map(\n",
    "    preprocess_function, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '593f14f960d971e294af884f0194b3a7',\n",
       " 'question': '舍本和誰的數據能推算出連星的恆星的質量？',\n",
       " 'paragraphs': [2018, 6952, 8264, 836],\n",
       " 'relevant': 836,\n",
       " 'answer': {'start': 108, 'text': '斯特魯維'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ed466149ca31f82a\n",
      "Found cached dataset json (/home/guest/r12922050/.cache/huggingface/datasets/json/default-ed466149ca31f82a/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 2/2 [00:00<00:00, 410.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data_files = {\n",
    "    'train': './data/train.json',\n",
    "    'validation': './data/valid.json',\n",
    "}\n",
    "\n",
    "my_datasets = load_dataset('json', data_files=data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim samples\n",
    "for split in my_datasets.keys():\n",
    "    my_datasets[split] = my_datasets[split].select(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 10.0kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 624/624 [00:00<00:00, 1.19MB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 37.3MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 269k/269k [00:00<00:00, 497kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator(gradient_accumulation_steps=2)\n",
    "from itertools import chain\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "if my_datasets[\"train\"] is not None:\n",
    "    column_names = my_datasets[\"train\"].column_names\n",
    "else:\n",
    "    column_names = my_datasets[\"validation\"].column_names\n",
    "\n",
    "context_name = \"question\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 4 for context in examples[context_name]]\n",
    "    second_sentences = []\n",
    "    labels = []\n",
    "    for i, paragraphs in enumerate(examples['paragraphs']):\n",
    "        correct_paragraph = examples['relevant'][i]\n",
    "        possible_ans = []\n",
    "        for ans_idx, paragraph in enumerate(paragraphs):\n",
    "            if paragraph == correct_paragraph:\n",
    "                labels.append(ans_idx)\n",
    "            possible_ans.append(paragraph_ref_map[paragraph])\n",
    "        second_sentences.append(possible_ans)\n",
    "\n",
    "    # Flatten out\n",
    "    first_sentences = list(chain(*first_sentences))\n",
    "    second_sentences = list(chain(*second_sentences))\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        max_length=args.max_seq_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "    )\n",
    "    # Un-flatten\n",
    "    tokenized_inputs = {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with accelerator.main_process_first():\n",
    "    processed_datasets = my_datasets.map(\n",
    "        preprocess_function, batched=True, remove_columns=my_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 13428 of the training set: 0.\n",
      "{'id': 'a6407580654244d6efdb31db964726ce', 'question': '印度全境炎熱，大部分屬於何種氣候?', 'paragraphs': [1812, 4272, 4849, 3443], 'relevant': 1812, 'answer': {'start': 744, 'text': '熱帶季風'}}\n"
     ]
    }
   ],
   "source": [
    "index = 13428\n",
    "print(f\"Sample {index} of the training set: {processed_datasets['train'][index]['labels']}.\")\n",
    "print(my_datasets[\"train\"][13428])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
